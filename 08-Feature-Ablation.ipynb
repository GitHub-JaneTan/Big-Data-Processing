{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8e7fa5-3cdf-4187-b3b7-f19259b27175",
   "metadata": {},
   "source": [
    "## 5.0 Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21358e7-3c1e-494b-be9a-20f9ccc69ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Tan Xin Hui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee31ea-e50c-496d-88c2-f7ecdae38edf",
   "metadata": {},
   "source": [
    "### 5.1 Determining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73fac6b-270a-44e2-aeba-4e710199020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/10 13:30:16 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model trained.\n",
      "Accuracy: 88.78%\n",
      "F1 Score: 0.8871\n",
      "Precision: 0.8868\n",
      "Recall: 0.8878\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "class RandomForestModeler:\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        self.spark = SparkSession.builder.appName(\"RandomForestModeler\").getOrCreate()\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.train_df = self.load_data(self.train_path)\n",
    "        self.test_df = self.load_data(self.test_path)\n",
    "\n",
    "    def load_data(self, path: str):\n",
    "        \"\"\"\n",
    "        Load dataset from the given HDFS path.\n",
    "        \"\"\"\n",
    "        return self.spark.read.csv(path, header=True, inferSchema=True)\n",
    "\n",
    "    def prepare_data(self, df, feature_cols, label_col):\n",
    "        \"\"\"\n",
    "        Prepares the dataset by assembling features into a single vector column.\n",
    "        \n",
    "        :param df: DataFrame containing the dataset.\n",
    "        :param feature_cols: List of column names to be used as features.\n",
    "        :param label_col: Column name to be used as the label.\n",
    "        \"\"\"\n",
    "        assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "        df_prepared = assembler.transform(df).select(\"features\", label_col)\n",
    "        return df_prepared\n",
    "\n",
    "    def train_random_forest(self, feature_cols, label_col, num_trees=10):\n",
    "        \"\"\"\n",
    "        Trains a Random Forest classifier on the training data.\n",
    "        \n",
    "        :param feature_cols: List of columns used as features.\n",
    "        :param label_col: Column used as the label.\n",
    "        :param num_trees: Number of trees in the Random Forest.\n",
    "        \"\"\"\n",
    "        # Prepare training data\n",
    "        train_data = self.prepare_data(self.train_df, feature_cols, label_col)\n",
    "\n",
    "        # Initialize the Random Forest Classifier\n",
    "        rf = RandomForestClassifier(featuresCol=\"features\", labelCol=label_col, numTrees=num_trees)\n",
    "        \n",
    "        # Train the model\n",
    "        self.rf_model = rf.fit(train_data)\n",
    "        print(\"Random Forest model trained.\")\n",
    "\n",
    "    def evaluate_model(self, feature_cols, label_col):\n",
    "        \"\"\"\n",
    "        Evaluates the trained Random Forest model on the test data using accuracy, F1 score, precision, and recall.\n",
    "        \n",
    "        :param feature_cols: List of columns used as features.\n",
    "        :param label_col: Column used as the label.\n",
    "        \"\"\"\n",
    "        # Prepare test data\n",
    "        test_data = self.prepare_data(self.test_df, feature_cols, label_col)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.rf_model.transform(test_data)\n",
    "\n",
    "        # Initialize evaluators for different metrics\n",
    "        accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        f1_evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "        precision_evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "        recall_evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "        f1_score = f1_evaluator.evaluate(predictions)\n",
    "        precision = precision_evaluator.evaluate(predictions)\n",
    "        recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Stops the Spark session.\n",
    "        \"\"\"\n",
    "        self.spark.stop()\n",
    "        print(\"Spark session stopped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_path = \"/user/student/train_data\"\n",
    "    test_path = \"/user/student/test_data\"\n",
    "\n",
    "    # Instantiate the RandomForestModeler\n",
    "    rf_modeler = RandomForestModeler(train_path, test_path)\n",
    "\n",
    "    # Specify features and label columns\n",
    "    feature_columns = ['Carat','Color_encoded'] \n",
    "    label_column = 'price_label'  \n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_modeler.train_random_forest(feature_cols=feature_columns, label_col=label_column, num_trees=20)\n",
    "    \n",
    "    #Metrics\n",
    "    metrics = rf_modeler.evaluate_model(feature_cols=feature_columns, label_col=label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2981a6-3455-4c72-82ea-1c3370ea88b6",
   "metadata": {},
   "source": [
    "#### HDFS Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27a411c-a3bc-43ed-99f8-fc78e7bf002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check saved train_data dataset\n",
    "class HDFSDataReader:\n",
    "    def __init__(self, hdfs_path: str):\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .appName(\"ReadHDFS\") \\\n",
    "            .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "            .getOrCreate()\n",
    "        self.hdfs_path = hdfs_path\n",
    "\n",
    "    def read_data(self) -> DataFrame:\n",
    "        self.df = self.spark.read.json(self.hdfs_path)\n",
    "        return self.df\n",
    "    \n",
    "    def read_csv(self, path: str) -> DataFrame:\n",
    "        self.df = self.spark.read.csv(path, header=True, inferSchema=True)\n",
    "        return self.df\n",
    "\n",
    "    def show_data(self, num_rows=5):\n",
    "        if hasattr(self, 'df'):\n",
    "            self.df.show(num_rows)\n",
    "        else:\n",
    "            print(\"DataFrame not loaded yet. Call read_data() or read_csv() first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12d607-a442-48c6-80e0-67a61315811f",
   "metadata": {},
   "source": [
    "### 5.2 Logarithmic and Root Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e8c5c4a-d5ef-4b75-8e48-76e086300df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor model trained.\n",
      "Root Mean Squared Error (RMSE) on test data = 101.25296827270557\n",
      "Mean Absolute Error (MAE) on test data = 55.45587683662959\n",
      "R-squared on test data = 0.999383244640879\n",
      "+--------------------+------+------------------+\n",
      "|            features| Price|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|(10,[0,6,7,8,9],[...|2696.0| 2697.464679658072|\n",
      "|(10,[0,5,7,8,9],[...|2802.0|2776.7803370912925|\n",
      "|(10,[0,7,8,9],[0....|2989.0| 2998.579181959588|\n",
      "|(10,[0,7,8,9],[0....|2989.0| 2998.579181959588|\n",
      "|(10,[0,5,7,8,9],[...|2991.0|2975.0576246914306|\n",
      "|(10,[0,7,8,9],[0....|3081.0|3116.3934946364107|\n",
      "|(10,[0,7,8,9],[0....|3290.0| 3273.023952194792|\n",
      "|(10,[0,7,8,9],[0....|3314.0| 3367.529403755707|\n",
      "|(10,[0,7,8,9],[0....|3314.0| 3367.529403755707|\n",
      "|(10,[0,7,8,9],[0....|3314.0| 3367.529403755707|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, log, sqrt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, train_df: DataFrame, test_df: DataFrame, feature_cols: list, label_col: str):\n",
    "        self.train_df = self.create_engineered_features(train_df)\n",
    "        self.test_df = self.create_engineered_features(test_df)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.label_col = label_col\n",
    "        \n",
    "        # Assemble features into a single vector column\n",
    "        self.feature_assembler = VectorAssembler(inputCols=self.feature_cols, outputCol='features')\n",
    "        self.train_df = self.feature_assembler.transform(self.train_df)\n",
    "        self.test_df = self.feature_assembler.transform(self.test_df)\n",
    "\n",
    "    def create_engineered_features(self, df: DataFrame) -> DataFrame:\n",
    "        # Example of novel features\n",
    "        df = df.withColumn('Carat_log', log(col('Carat') + 1))\n",
    "        df = df.withColumn('Carat_sqrt', sqrt(col('Carat')))\n",
    "        df = df.withColumn('Price_log', log(col('Price') + 1))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def train(self, max_iter: int = 100):\n",
    "        gbt = GBTRegressor(\n",
    "            featuresCol='features',\n",
    "            labelCol=self.label_col,\n",
    "            maxIter=max_iter\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        self.model = gbt.fit(self.train_df)\n",
    "        print(\"Gradient Boosting Regressor model trained.\")\n",
    "    \n",
    "    def evaluate(self):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained.\")\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.model.transform(self.test_df)\n",
    "        \n",
    "        # Initialize evaluators for different metrics\n",
    "        evaluator_rmse = RegressionEvaluator(labelCol=self.label_col, predictionCol='prediction', metricName='rmse')\n",
    "        evaluator_mae = RegressionEvaluator(labelCol=self.label_col, predictionCol='prediction', metricName='mae')\n",
    "        evaluator_r2 = RegressionEvaluator(labelCol=self.label_col, predictionCol='prediction', metricName='r2')\n",
    "        \n",
    "        # Compute metrics\n",
    "        rmse = evaluator_rmse.evaluate(predictions)\n",
    "        mae = evaluator_mae.evaluate(predictions)\n",
    "        r2 = evaluator_r2.evaluate(predictions)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "        print(f\"Mean Absolute Error (MAE) on test data = {mae}\")\n",
    "        print(f\"R-squared on test data = {r2}\")\n",
    "\n",
    "        # Show some predictions\n",
    "        predictions.select('features', self.label_col, 'prediction').show(10)\n",
    "        \n",
    "        return {\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_path = \"/user/student/train_data\"\n",
    "    test_path = \"/user/student/test_data\"\n",
    "\n",
    "    train_reader = HDFSDataReader(train_path)\n",
    "    hdfs_reader = HDFSDataReader(train_path)\n",
    "    \n",
    "    train_df = train_reader.read_csv(train_path)\n",
    "    test_df = hdfs_reader.read_csv(test_path)\n",
    "    \n",
    "    # Specify features and label columns\n",
    "    feature_columns = ['Carat', 'Shape_encoded', 'Clarity_encoded', 'Color_encoded', 'Polish_encoded', 'Symmetry_encoded', 'Fluorescence_encoded', 'Carat_log','Carat_sqrt', 'Price_log']\n",
    "    label_column = 'Price' \n",
    "    \n",
    "    # Initialize GradientBoostingRegressor with train and test datasets\n",
    "    gbt_regressor = GradientBoostingRegressor(train_df=train_df, test_df=test_df, feature_cols=feature_columns, label_col=label_column)\n",
    "    \n",
    "    # Train the Gradient Boosting model\n",
    "    gbt_regressor.train(max_iter=100)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = gbt_regressor.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3a481-3544-48e5-b8bc-7f68fea8fc12",
   "metadata": {},
   "source": [
    "### 5.3 Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709aef6-9f9d-419e-9491-c77f6d9b8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, log, sqrt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, train_df: DataFrame, test_df: DataFrame, feature_cols: list, label_col: str):\n",
    "        self.train_df = self.create_interaction_features(train_df)\n",
    "        self.test_df = self.create_interaction_features(test_df)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.label_col = label_col\n",
    "        \n",
    "        # Assemble features into a single vector column\n",
    "        self.feature_assembler = VectorAssembler(inputCols=self.feature_cols, outputCol='features')\n",
    "        self.train_df = self.feature_assembler.transform(self.train_df)\n",
    "        self.test_df = self.feature_assembler.transform(self.test_df)\n",
    "\n",
    "    def create_interaction_features(self, df: DataFrame) -> DataFrame:\n",
    "        df = df.withColumn('Carat_Color_Interaction', col('Carat') * col('Color_encoded'))\n",
    "        df = df.withColumn('Carat_Clarity_Interaction', col('Carat') * col('Clarity_encoded'))\n",
    "        df = df.withColumn('Carat_Polish_Interaction', col('Carat') * col('Polish_encoded'))\n",
    "        df = df.withColumn('Carat_Symmetry_Interaction', col('Carat') * col('Symmetry_encoded'))\n",
    "        df = df.withColumn('Carat_Fluorescence_Interaction', col('Carat') * col('Fluorescence_encoded'))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def train(self, max_iter: int = 100):\n",
    "        \"\"\"\n",
    "        Train a Gradient Boosted Trees Regressor model.\n",
    "        \"\"\"\n",
    "        gbt = GBTRegressor(\n",
    "            featuresCol='features',\n",
    "            labelCol=self.label_col,\n",
    "            maxIter=max_iter\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        self.model = gbt.fit(self.train_df)\n",
    "        print(\"Gradient Boosting Regressor model trained.\")\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the Gradient Boosting model using the test dataset.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained.\")\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.model.transform(self.test_df)\n",
    "        \n",
    "        # Initialize evaluators for different metrics\n",
    "        evaluator_rmse = RegressionEvaluator(labelCol=self.label_col, predictionCol='prediction', metricName='rmse')\n",
    "        evaluator_mae = RegressionEvaluator(labelCol=self.label_col, predictionCol='prediction', metricName='mae')\n",
    "        evaluator_r2 = RegressionEvaluator(labelCol=self.label_col, predictionCol='prediction', metricName='r2')\n",
    "        \n",
    "        # Compute metrics\n",
    "        rmse = evaluator_rmse.evaluate(predictions)\n",
    "        mae = evaluator_mae.evaluate(predictions)\n",
    "        r2 = evaluator_r2.evaluate(predictions)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "        print(f\"Mean Absolute Error (MAE) on test data = {mae}\")\n",
    "        print(f\"R-squared on test data = {r2}\")\n",
    "\n",
    "        # Show some predictions\n",
    "        predictions.select('features', self.label_col, 'prediction').show(10)\n",
    "        \n",
    "        return {\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_path = \"/user/student/train_data\"\n",
    "    test_path = \"/user/student/test_data\"\n",
    "\n",
    "    train_df = hdfs_reader.read_csv(train_path)\n",
    "    test_df = hdfs_reader.read_csv(test_path)\n",
    "    \n",
    "    # Specify features and label columns\n",
    "    label_column = 'Price'  \n",
    "    feature_columns = ['Carat', 'Color_encoded', 'Clarity_encoded', 'Polish_encoded', 'Symmetry_encoded', 'Fluorescence_encoded', \n",
    "                       'Carat_Color_Interaction', 'Carat_Clarity_Interaction', 'Carat_Polish_Interaction', 'Carat_Symmetry_Interaction', \n",
    "                       'Carat_Fluorescence_Interaction']\n",
    "    \n",
    "    # Initialize GradientBoostingRegressor with train and test datasets\n",
    "    gbt_regressor = GradientBoostingRegressor(train_df=train_df, test_df=test_df, feature_cols=feature_columns, label_col=label_column)\n",
    "    \n",
    "    # Train the Gradient Boosting model\n",
    "    gbt_regressor.train(max_iter=100)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = gbt_regressor.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506cd75-b6e7-4b3d-8833-e737233f5c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
